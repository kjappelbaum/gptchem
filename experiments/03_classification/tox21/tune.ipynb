{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.molnet import load_tox21\n",
    "import numpy as np\n",
    "from gptchem.tuner import Tuner\n",
    "from gptchem.gpt_classifier import GPTClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pubchempy import get_compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name for a SMILES using pubchempy\n",
    "\n",
    "def get_name(smiles):\n",
    "    try:\n",
    "        return get_compounds(smiles, 'smiles')[0].iupac_name\n",
    "    except:\n",
    "        return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_tasks, tox21_datasets, transformers = load_tox21(seed=21, reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = tox21_datasets\n",
    "\n",
    "X_train, y_train = train_dataset.ids, train_dataset.y[:, -1]\n",
    "X_test, y_test = test_dataset.ids, test_dataset.y[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [get_name(smiles) for smiles in X_train]\n",
    "test_names = [get_name(smiles) for smiles in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C=C(C)C(=O)OCCCCCCCCCCCCC'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(len(X_train), size=6000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[train_indices].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(random_state=42)\n",
    "X_train, y_train = sampler.fit_resample(X_train[train_indices].reshape(-1,1), y_train[train_indices].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(train_names)[train_indices]\n",
    "# y_train = y_train[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'names': X_train.flatten(), 'label': y_train.flatten()})\n",
    "df_train = df_train.dropna(subset=['names'])\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame({'names': X_test, 'label': y_test})\n",
    "df_test = df_test.dropna(subset=['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GPTClassifier(\n",
    "    'activity', \n",
    " tuner=Tuner(n_epochs=4, learning_rate_multiplier=0.02)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 58.7k/58.7k [00:00<00:00, 102Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from /Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/tox21/out/20231006_083128/train.jsonl: file-7o5T63H0g3B6BcItMCTp23eH\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fine tuning failed. Result: {\n  \"object\": \"fine-tune\",\n  \"id\": \"ft-3SuVEwP4iTSBcdm0i0FBWe0l\",\n  \"hyperparams\": {\n    \"n_epochs\": 4,\n    \"batch_size\": null,\n    \"prompt_loss_weight\": 0.01,\n    \"learning_rate_multiplier\": 0.02\n  },\n  \"organization_id\": \"org-eRwftHUvPVthUUPGPm4T2j0U\",\n  \"model\": \"ada\",\n  \"training_files\": [\n    {\n      \"object\": \"file\",\n      \"id\": \"file-7o5T63H0g3B6BcItMCTp23eH\",\n      \"purpose\": \"fine-tune\",\n      \"filename\": \"/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/tox21/out/20231006_083128/train.jsonl\",\n      \"bytes\": 58712,\n      \"created_at\": 1696573895,\n      \"status\": \"uploaded\",\n      \"status_details\": null\n    }\n  ],\n  \"validation_files\": [],\n  \"result_files\": [],\n  \"created_at\": 1696573895,\n  \"updated_at\": 1696573895,\n  \"status\": \"pending\",\n  \"fine_tuned_model\": null,\n  \"events\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"level\": \"info\",\n      \"message\": \"Created fine-tune: ft-3SuVEwP4iTSBcdm0i0FBWe0l\",\n      \"created_at\": 1696573895\n    }\n  ]\n}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/tox21/tune.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/tox21/tune.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(df_train[\u001b[39m'\u001b[39;49m\u001b[39mnames\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues, df_train[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\u001b[39m.\u001b[39;49mvalues)\n",
      "File \u001b[0;32m~/git/kjappelbaum/gptchem/src/gptchem/gpt_classifier.py:79\u001b[0m, in \u001b[0;36mGPTClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_df(X, y)\n\u001b[1;32m     78\u001b[0m formatted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformatter(df)\n\u001b[0;32m---> 79\u001b[0m tune_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner(formatted)\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m tune_res[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtune_res \u001b[39m=\u001b[39m tune_res\n",
      "File \u001b[0;32m~/git/kjappelbaum/gptchem/src/gptchem/tuner.py:220\u001b[0m, in \u001b[0;36mTuner.__call__\u001b[0;34m(self, train_df, validation_df)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m, train_df: pd\u001b[39m.\u001b[39mDataFrame, validation_df: Optional[pd\u001b[39m.\u001b[39mDataFrame] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtune(train_df, validation_df)\n",
      "File \u001b[0;32m~/git/kjappelbaum/gptchem/src/gptchem/tuner.py:206\u001b[0m, in \u001b[0;36mTuner.tune\u001b[0;34m(self, train_df, validation_df)\u001b[0m\n\u001b[1;32m    203\u001b[0m     logger\u001b[39m.\u001b[39mexception(\u001b[39m\"\u001b[39m\u001b[39mFine tuning failed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m modelname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFine tuning failed. Result: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modelname \u001b[39m=\u001b[39m modelname\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ft_id \u001b[39m=\u001b[39m ft_id\n",
      "\u001b[0;31mValueError\u001b[0m: Fine tuning failed. Result: {\n  \"object\": \"fine-tune\",\n  \"id\": \"ft-3SuVEwP4iTSBcdm0i0FBWe0l\",\n  \"hyperparams\": {\n    \"n_epochs\": 4,\n    \"batch_size\": null,\n    \"prompt_loss_weight\": 0.01,\n    \"learning_rate_multiplier\": 0.02\n  },\n  \"organization_id\": \"org-eRwftHUvPVthUUPGPm4T2j0U\",\n  \"model\": \"ada\",\n  \"training_files\": [\n    {\n      \"object\": \"file\",\n      \"id\": \"file-7o5T63H0g3B6BcItMCTp23eH\",\n      \"purpose\": \"fine-tune\",\n      \"filename\": \"/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/tox21/out/20231006_083128/train.jsonl\",\n      \"bytes\": 58712,\n      \"created_at\": 1696573895,\n      \"status\": \"uploaded\",\n      \"status_details\": null\n    }\n  ],\n  \"validation_files\": [],\n  \"result_files\": [],\n  \"created_at\": 1696573895,\n  \"updated_at\": 1696573895,\n  \"status\": \"pending\",\n  \"fine_tuned_model\": null,\n  \"events\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"level\": \"info\",\n      \"message\": \"Created fine-tune: ft-3SuVEwP4iTSBcdm0i0FBWe0l\",\n      \"created_at\": 1696573895\n    }\n  ]\n}."
     ]
    }
   ],
   "source": [
    "classifier.fit(df_train['names'].values, df_train['label'].astype(int).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gptchem.gpt_classifier.GPTClassifier at 0x179919580>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.random.choice(len(X_test), size=200, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(df_test['names'].values[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict   0         1         \n",
      "Actual\n",
      "0         180       0         \n",
      "\n",
      "1         20        0         \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.85842,0.94158)\n",
      "ACC Macro                                                         0.9\n",
      "ARI                                                               0.0\n",
      "AUNP                                                              0.5\n",
      "AUNU                                                              0.5\n",
      "Bangdiwala B                                                      0.9\n",
      "Bennett S                                                         0.8\n",
      "CBA                                                               0.45\n",
      "CSI                                                               None\n",
      "Chi-Squared                                                       None\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               -0.0\n",
      "Cramer V                                                          None\n",
      "Cross Entropy                                                     -0.0\n",
      "F1 Macro                                                          0.47368\n",
      "F1 Micro                                                          0.9\n",
      "FNR Macro                                                         0.5\n",
      "FNR Micro                                                         0.1\n",
      "FPR Macro                                                         0.5\n",
      "FPR Micro                                                         0.1\n",
      "Gwet AC1                                                          0.8895\n",
      "Hamming Loss                                                      0.1\n",
      "Joint Entropy                                                     0.469\n",
      "KL Divergence                                                     None\n",
      "Kappa                                                             0.0\n",
      "Kappa 95% CI                                                      (-0.41578,0.41578)\n",
      "Kappa No Prevalence                                               0.8\n",
      "Kappa Standard Error                                              0.21213\n",
      "Kappa Unbiased                                                    -0.05263\n",
      "Krippendorff Alpha                                                -0.05\n",
      "Lambda A                                                          0.0\n",
      "Lambda B                                                          None\n",
      "Mutual Information                                                0.0\n",
      "NIR                                                               0.9\n",
      "Overall ACC                                                       0.9\n",
      "Overall CEN                                                       0.2124\n",
      "Overall J                                                         (0.9,0.45)\n",
      "Overall MCC                                                       None\n",
      "Overall MCEN                                                      0.1661\n",
      "Overall RACC                                                      0.9\n",
      "Overall RACCU                                                     0.905\n",
      "P-Value                                                           0.55917\n",
      "PPV Macro                                                         None\n",
      "PPV Micro                                                         0.9\n",
      "Pearson C                                                         None\n",
      "Phi-Squared                                                       None\n",
      "RCI                                                               0.0\n",
      "RR                                                                100.0\n",
      "Reference Entropy                                                 0.469\n",
      "Response Entropy                                                  -0.0\n",
      "SOA1(Landis & Koch)                                               Slight\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Poor\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "SOA5(Cramer)                                                      None\n",
      "SOA6(Matthews)                                                    None\n",
      "Scott PI                                                          -0.05263\n",
      "Standard Error                                                    0.02121\n",
      "TNR Macro                                                         0.5\n",
      "TNR Micro                                                         0.9\n",
      "TPR Macro                                                         0.5\n",
      "TPR Micro                                                         0.9\n",
      "Zero-one Loss                                                     20\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.9           0.9           \n",
      "AGF(Adjusted F-score)                                             0.0           0.0           \n",
      "AGM(Adjusted geometric mean)                                      0.0           0             \n",
      "AM(Difference between automatic and manual classification)        20            -20           \n",
      "AUC(Area under the ROC curve)                                     0.5           0.5           \n",
      "AUCI(AUC value interpretation)                                    Poor          Poor          \n",
      "AUPR(Area under the PR curve)                                     0.95          None          \n",
      "BB(Braun-Blanquet similarity)                                     0.9           0.0           \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.05          0.05          \n",
      "BM(Informedness or bookmaker informedness)                        0.0           0.0           \n",
      "CEN(Confusion entropy)                                            0.22358       0.0           \n",
      "DOR(Diagnostic odds ratio)                                        None          None          \n",
      "DP(Discriminant power)                                            None          None          \n",
      "DPI(Discriminant power interpretation)                            None          None          \n",
      "ERR(Error rate)                                                   0.1           0.1           \n",
      "F0.5(F0.5 score)                                                  0.91837       0.0           \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.94737       0.0           \n",
      "F2(F2 score)                                                      0.97826       0.0           \n",
      "FDR(False discovery rate)                                         0.1           None          \n",
      "FN(False negative/miss/type 2 error)                              0             20            \n",
      "FNR(Miss rate or false negative rate)                             0.0           1.0           \n",
      "FOR(False omission rate)                                          None          0.1           \n",
      "FP(False positive/type 1 error/false alarm)                       20            0             \n",
      "FPR(Fall-out or false positive rate)                              1.0           0.0           \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.94868       None          \n",
      "GI(Gini index)                                                    0.0           0.0           \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.0           0.0           \n",
      "HD(Hamming distance)                                              20            20            \n",
      "IBA(Index of balanced accuracy)                                   0.0           0.0           \n",
      "ICSI(Individual classification success index)                     0.9           None          \n",
      "IS(Information score)                                             0.0           None          \n",
      "J(Jaccard index)                                                  0.9           0.0           \n",
      "LS(Lift score)                                                    1.0           None          \n",
      "MCC(Matthews correlation coefficient)                             None          None          \n",
      "MCCI(Matthews correlation coefficient interpretation)             None          None          \n",
      "MCEN(Modified confusion entropy)                                  0.33219       0.0           \n",
      "MK(Markedness)                                                    None          None          \n",
      "N(Condition negative)                                             20            180           \n",
      "NLR(Negative likelihood ratio)                                    None          1.0           \n",
      "NLRI(Negative likelihood ratio interpretation)                    None          Negligible    \n",
      "NPV(Negative predictive value)                                    None          0.9           \n",
      "OC(Overlap coefficient)                                           1.0           None          \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.94868       None          \n",
      "OP(Optimized precision)                                           -0.1          -0.1          \n",
      "P(Condition positive or support)                                  180           20            \n",
      "PLR(Positive likelihood ratio)                                    1.0           None          \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          None          \n",
      "POP(Population)                                                   200           200           \n",
      "PPV(Precision or positive predictive value)                       0.9           None          \n",
      "PRE(Prevalence)                                                   0.9           0.1           \n",
      "Q(Yule Q - coefficient of colligation)                            None          None          \n",
      "QI(Yule Q interpretation)                                         None          None          \n",
      "RACC(Random accuracy)                                             0.9           0.0           \n",
      "RACCU(Random accuracy unbiased)                                   0.9025        0.0025        \n",
      "TN(True negative/correct rejection)                               0             180           \n",
      "TNR(Specificity or true negative rate)                            0.0           1.0           \n",
      "TON(Test outcome negative)                                        0             200           \n",
      "TOP(Test outcome positive)                                        200           0             \n",
      "TP(True positive/hit)                                             180           0             \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         1.0           0.0           \n",
      "Y(Youden index)                                                   0.0           0.0           \n",
      "dInd(Distance index)                                              1.0           1.0           \n",
      "sInd(Similarity index)                                            0.29289       0.29289       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ConfusionMatrix(actual_vector=df_test['label'].values[test_indices].astype(int), predict_vector=list(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
