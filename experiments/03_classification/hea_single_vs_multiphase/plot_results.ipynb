{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import pandas as pd \n",
    "from fastcore.xtras import load_pickle \n",
    "\n",
    "from gptchem.data import get_hea_phase_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from gptchem.evaluator import evaluate_classification\n",
    "from gptchem.formatter import ClassificationFormatter\n",
    "from gptchem.settings import ONE_COL_WIDTH_INCH, TWO_COL_GOLDEN_RATIO_HEIGHT_INCH\n",
    "\n",
    "\n",
    "from scipy.stats import sem\n",
    "\n",
    "import matplotx\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use(['science', 'nature'])\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dummy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_hea_phase_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = ['uniform', 'stratified', 'most_frequent']\n",
    "results = []\n",
    "train_sizes = [10, 20, 50, 100, 200]\n",
    "for i in range(10): \n",
    "    for estimator in estimators:\n",
    "        for train_size in train_sizes: \n",
    "            train, test = train_test_split(data, train_size=train_size, test_size=250, stratify=data['phase_binary_encoded'], random_state=i) \n",
    "            classifier = DummyClassifier(strategy=estimator)\n",
    "            classifier.fit(train['Alloy'], train['phase_binary_encoded'])\n",
    "            predictions = classifier.predict(test['Alloy'])\n",
    "            res = evaluate_classification(test['phase_binary_encoded'], predictions)\n",
    "            res['train_size'] = train_size\n",
    "            res['estimator'] = estimator\n",
    "            results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_grouped = dummy_results[['train_size', 'estimator', 'accuracy', 'f1_macro', 'f1_micro', 'kappa']].groupby([ 'estimator', 'train_size']).agg(['mean', 'std', sem]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimator</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">most_frequent</th>\n",
       "      <th>10</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">stratified</th>\n",
       "      <th>10</th>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.027159</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.503037</td>\n",
       "      <td>0.027244</td>\n",
       "      <td>8.615207e-03</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.027159</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>0.017177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5092</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.508548</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>1.127320e-02</td>\n",
       "      <td>0.5092</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.070960</td>\n",
       "      <td>0.022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.045724</td>\n",
       "      <td>0.014459</td>\n",
       "      <td>0.487412</td>\n",
       "      <td>0.046046</td>\n",
       "      <td>1.456104e-02</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.045724</td>\n",
       "      <td>0.014459</td>\n",
       "      <td>-0.0240</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>0.028918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.514626</td>\n",
       "      <td>0.026420</td>\n",
       "      <td>8.354599e-03</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.052770</td>\n",
       "      <td>0.016687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>0.483574</td>\n",
       "      <td>0.037671</td>\n",
       "      <td>1.191247e-02</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>0.075278</td>\n",
       "      <td>0.023805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">uniform</th>\n",
       "      <th>10</th>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.483611</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>8.076721e-03</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.015677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.512279</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>7.639182e-03</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.047822</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.030137</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.495154</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>9.466834e-03</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.030137</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>0.060275</td>\n",
       "      <td>0.019061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.034935</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.517765</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>1.106204e-02</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.034935</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>0.022095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.4804</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.479882</td>\n",
       "      <td>0.031917</td>\n",
       "      <td>1.009316e-02</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.063716</td>\n",
       "      <td>0.020149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy                      f1_macro            \\\n",
       "                             mean       std       sem      mean       std   \n",
       "estimator     train_size                                                    \n",
       "most_frequent 10           0.5000  0.000000  0.000000  0.333333  0.000000   \n",
       "              20           0.5000  0.000000  0.000000  0.333333  0.000000   \n",
       "              50           0.5000  0.000000  0.000000  0.333333  0.000000   \n",
       "              100          0.5000  0.000000  0.000000  0.333333  0.000000   \n",
       "              200          0.5000  0.000000  0.000000  0.333333  0.000000   \n",
       "stratified    10           0.5036  0.027159  0.008588  0.503037  0.027244   \n",
       "              20           0.5092  0.035480  0.011220  0.508548  0.035649   \n",
       "              50           0.4880  0.045724  0.014459  0.487412  0.046046   \n",
       "              100          0.5152  0.026385  0.008344  0.514626  0.026420   \n",
       "              200          0.4844  0.037639  0.011903  0.483574  0.037671   \n",
       "uniform       10           0.4848  0.024787  0.007838  0.483611  0.025541   \n",
       "              20           0.5128  0.023911  0.007561  0.512279  0.024157   \n",
       "              50           0.4956  0.030137  0.009530  0.495154  0.029937   \n",
       "              100          0.5180  0.034935  0.011047  0.517765  0.034981   \n",
       "              200          0.4804  0.031858  0.010074  0.479882  0.031917   \n",
       "\n",
       "                                       f1_micro                       kappa  \\\n",
       "                                   sem     mean       std       sem    mean   \n",
       "estimator     train_size                                                      \n",
       "most_frequent 10          1.850372e-17   0.5000  0.000000  0.000000  0.0000   \n",
       "              20          1.850372e-17   0.5000  0.000000  0.000000  0.0000   \n",
       "              50          1.850372e-17   0.5000  0.000000  0.000000  0.0000   \n",
       "              100         1.850372e-17   0.5000  0.000000  0.000000  0.0000   \n",
       "              200         1.850372e-17   0.5000  0.000000  0.000000  0.0000   \n",
       "stratified    10          8.615207e-03   0.5036  0.027159  0.008588  0.0072   \n",
       "              20          1.127320e-02   0.5092  0.035480  0.011220  0.0184   \n",
       "              50          1.456104e-02   0.4880  0.045724  0.014459 -0.0240   \n",
       "              100         8.354599e-03   0.5152  0.026385  0.008344  0.0304   \n",
       "              200         1.191247e-02   0.4844  0.037639  0.011903 -0.0312   \n",
       "uniform       10          8.076721e-03   0.4848  0.024787  0.007838 -0.0304   \n",
       "              20          7.639182e-03   0.5128  0.023911  0.007561  0.0256   \n",
       "              50          9.466834e-03   0.4956  0.030137  0.009530 -0.0088   \n",
       "              100         1.106204e-02   0.5180  0.034935  0.011047  0.0360   \n",
       "              200         1.009316e-02   0.4804  0.031858  0.010074 -0.0392   \n",
       "\n",
       "                                              \n",
       "                               std       sem  \n",
       "estimator     train_size                      \n",
       "most_frequent 10          0.000000  0.000000  \n",
       "              20          0.000000  0.000000  \n",
       "              50          0.000000  0.000000  \n",
       "              100         0.000000  0.000000  \n",
       "              200         0.000000  0.000000  \n",
       "stratified    10          0.054318  0.017177  \n",
       "              20          0.070960  0.022440  \n",
       "              50          0.091448  0.028918  \n",
       "              100         0.052770  0.016687  \n",
       "              200         0.075278  0.023805  \n",
       "uniform       10          0.049574  0.015677  \n",
       "              20          0.047822  0.015123  \n",
       "              50          0.060275  0.019061  \n",
       "              100         0.069870  0.022095  \n",
       "              200         0.063716  0.020149  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = glob(\"out/**/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = [load_pickle(p) for p in all_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_res = []\n",
    "\n",
    "for out in all_out: \n",
    "    res = {\n",
    "        'base_model': out['base_model'],\n",
    "        'train_size': out['train_size'],\n",
    "        'test_size': out['test_size'],\n",
    "        'n_epochs': out['n_epochs'],\n",
    "        'learning_rate_multiplier': out['learning_rate_multiplier'],\n",
    "        'frac_valid': out['frac_valid'],\n",
    "        'accuracy': out['accuracy'],\n",
    "        'f1_macro': out['f1_macro'],\n",
    "        'f1_micro': out['f1_micro'],\n",
    "        'kappa': out['kappa'],\n",
    "    }\n",
    "\n",
    "    extracted_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_res = pd.DataFrame(extracted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_62610/1554210877.py:1: FutureWarning: ['base_model'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  extracted_res_grouped = extracted_res.groupby(['train_size']).agg(['mean', 'std', sem])\n"
     ]
    }
   ],
   "source": [
    "extracted_res_grouped = extracted_res.groupby(['train_size']).agg(['mean', 'std', sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test_size</th>\n",
       "      <th colspan=\"3\" halign=\"left\">n_epochs</th>\n",
       "      <th colspan=\"3\" halign=\"left\">learning_rate_multiplier</th>\n",
       "      <th>frac_valid</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.156482e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.884522</td>\n",
       "      <td>0.047488</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>0.045848</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.771200</td>\n",
       "      <td>0.091696</td>\n",
       "      <td>0.028997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.156482e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.890336</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.017712</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.783200</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>0.034532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.156482e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.932225</td>\n",
       "      <td>0.033577</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.932400</td>\n",
       "      <td>0.033224</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.864800</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.021013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.960406</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.960444</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.920889</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.010620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.156482e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.964376</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.928800</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.005393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_size           n_epochs           learning_rate_multiplier  \\\n",
       "                mean  std  sem     mean  std  sem                     mean   \n",
       "train_size                                                                   \n",
       "10             250.0  0.0  0.0      8.0  0.0  0.0                     0.02   \n",
       "20             250.0  0.0  0.0      8.0  0.0  0.0                     0.02   \n",
       "50             250.0  0.0  0.0      8.0  0.0  0.0                     0.02   \n",
       "100            250.0  0.0  0.0      8.0  0.0  0.0                     0.02   \n",
       "200            250.0  0.0  0.0      8.0  0.0  0.0                     0.02   \n",
       "\n",
       "                              frac_valid  ...  accuracy  f1_macro            \\\n",
       "            std           sem       mean  ...       sem      mean       std   \n",
       "train_size                                ...                                 \n",
       "10          0.0  1.156482e-18        1.0  ...  0.014498  0.884522  0.047488   \n",
       "20          0.0  1.156482e-18        1.0  ...  0.017266  0.890336  0.056011   \n",
       "50          0.0  1.156482e-18        1.0  ...  0.010506  0.932225  0.033577   \n",
       "100         0.0  0.000000e+00        1.0  ...  0.005310  0.960406  0.015974   \n",
       "200         0.0  1.156482e-18        1.0  ...  0.002696  0.964376  0.008544   \n",
       "\n",
       "                      f1_micro                         kappa            \\\n",
       "                 sem      mean       std       sem      mean       std   \n",
       "train_size                                                               \n",
       "10          0.015017  0.885600  0.045848  0.014498  0.771200  0.091696   \n",
       "20          0.017712  0.891600  0.054600  0.017266  0.783200  0.109200   \n",
       "50          0.010618  0.932400  0.033224  0.010506  0.864800  0.066448   \n",
       "100         0.005325  0.960444  0.015930  0.005310  0.920889  0.031861   \n",
       "200         0.002702  0.964400  0.008527  0.002696  0.928800  0.017054   \n",
       "\n",
       "                      \n",
       "                 sem  \n",
       "train_size            \n",
       "10          0.028997  \n",
       "20          0.034532  \n",
       "50          0.021013  \n",
       "100         0.010620  \n",
       "200         0.005393  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_res_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 325x444.984 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with plt.style.context(matplotx.styles.dufte):\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(ONE_COL_WIDTH_INCH, TWO_COL_GOLDEN_RATIO_HEIGHT_INCH), sharex='all')\n",
    "\n",
    "    # accuracy\n",
    "    ax[0].plot(\n",
    "        extracted_res_grouped.index, \n",
    "        extracted_res_grouped['accuracy']['mean'],\n",
    "        marker='o',\n",
    "        label='GPT-3',\n",
    "    )\n",
    "    ax[0].fill_between(\n",
    "        extracted_res_grouped.index,\n",
    "        extracted_res_grouped['accuracy']['mean'] - extracted_res_grouped['accuracy']['sem'],\n",
    "        extracted_res_grouped['accuracy']['mean'] + extracted_res_grouped['accuracy']['sem'],\n",
    "        alpha=.2,\n",
    "        color='C0',\n",
    "    )\n",
    "    \n",
    "\n",
    "    #add the dummy models \n",
    "    for i, estimator in enumerate(estimators):\n",
    "        ax[0].plot(\n",
    "            dummy_grouped.loc[estimator, :]['accuracy']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['accuracy']['mean'],\n",
    "            label=estimator.replace('_', ' '),\n",
    "            marker='o',\n",
    "            color=f'C{i+1}'\n",
    "        )\n",
    "        ax[0].fill_between(\n",
    "            dummy_grouped.loc[estimator, :]['accuracy']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['accuracy']['mean'] - dummy_grouped.loc[estimator, :]['accuracy']['sem'],\n",
    "            dummy_grouped.loc[estimator, :]['accuracy']['mean'] + dummy_grouped.loc[estimator, :]['accuracy']['sem'],\n",
    "            alpha=.2,\n",
    "            color=f'C{i+1}',\n",
    "        )\n",
    "\n",
    "    # f1 macro \n",
    "    ax[1].plot(\n",
    "        extracted_res_grouped.index, \n",
    "        extracted_res_grouped['f1_macro']['mean'],\n",
    "        label='GPT-3',\n",
    "        marker='o',\n",
    "    )\n",
    "    ax[1].fill_between(\n",
    "        extracted_res_grouped.index,\n",
    "        extracted_res_grouped['f1_macro']['mean'] - extracted_res_grouped['f1_macro']['sem'],\n",
    "        extracted_res_grouped['f1_macro']['mean'] + extracted_res_grouped['f1_macro']['sem'],\n",
    "        alpha=.2,\n",
    "        color='C0',\n",
    "    )\n",
    "\n",
    "    # add the dummy models \n",
    "    for i, estimator in enumerate(estimators):\n",
    "        ax[1].plot(\n",
    "            dummy_grouped.loc[estimator, :]['f1_macro']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['f1_macro']['mean'],\n",
    "            label=estimator.replace('_', ' '),\n",
    "            marker='o',\n",
    "            color=f'C{i+1}'\n",
    "        )\n",
    "        ax[1].fill_between(\n",
    "            dummy_grouped.loc[estimator, :]['f1_macro']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['f1_macro']['mean'] - dummy_grouped.loc[estimator, :]['f1_macro']['sem'],\n",
    "            dummy_grouped.loc[estimator, :]['f1_macro']['mean'] + dummy_grouped.loc[estimator, :]['f1_macro']['sem'],\n",
    "            alpha=.2,\n",
    "            color=f'C{i+1}',\n",
    "        )\n",
    "\n",
    "    # f1 micro \n",
    "\n",
    "    ax[2].plot(\n",
    "        extracted_res_grouped.index, \n",
    "        extracted_res_grouped['f1_micro']['mean'],\n",
    "        label='GPT-3',\n",
    "        marker='o',\n",
    "    )\n",
    "    ax[2].fill_between(\n",
    "        extracted_res_grouped.index,\n",
    "        extracted_res_grouped['f1_micro']['mean'] - extracted_res_grouped['f1_micro']['sem'],\n",
    "        extracted_res_grouped['f1_micro']['mean'] + extracted_res_grouped['f1_micro']['sem'],\n",
    "        alpha=.2,\n",
    "        color='C0',\n",
    "    )\n",
    "\n",
    "    # add the dummy models \n",
    "    for i, estimator in enumerate(estimators):\n",
    "        ax[2].plot(\n",
    "            dummy_grouped.loc[estimator, :]['f1_micro']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['f1_micro']['mean'],\n",
    "            label=estimator.replace('_', ' '),\n",
    "            marker='o',\n",
    "            color=f'C{i+1}'\n",
    "        )\n",
    "        ax[2].fill_between(\n",
    "            dummy_grouped.loc[estimator, :]['f1_micro']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['f1_micro']['mean'] - dummy_grouped.loc[estimator, :]['f1_micro']['sem'],\n",
    "            dummy_grouped.loc[estimator, :]['f1_micro']['mean'] + dummy_grouped.loc[estimator, :]['f1_micro']['sem'],\n",
    "            alpha=.2,\n",
    "            color=f'C{i+1}',\n",
    "        )\n",
    "\n",
    "\n",
    "    # kappa\n",
    "    ax[3].plot(\n",
    "        extracted_res_grouped.index, \n",
    "        extracted_res_grouped['kappa']['mean'],\n",
    "        label='GPT-3',\n",
    "        marker='o',\n",
    "    )\n",
    "    ax[3].fill_between(\n",
    "        extracted_res_grouped.index,\n",
    "        extracted_res_grouped['kappa']['mean'] - extracted_res_grouped['kappa']['sem'],\n",
    "        extracted_res_grouped['kappa']['mean'] + extracted_res_grouped['kappa']['sem'],\n",
    "        alpha=.2,\n",
    "        color='C0',\n",
    "    )\n",
    "\n",
    "    # add the dummy models \n",
    "    for i, estimator in enumerate(estimators):\n",
    "        ax[3].plot(\n",
    "            dummy_grouped.loc[estimator, :]['kappa']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['kappa']['mean'],\n",
    "            label=estimator.replace('_', ' '),\n",
    "            marker='o',\n",
    "            color=f'C{i+1}'\n",
    "        )\n",
    "        ax[3].fill_between(\n",
    "            dummy_grouped.loc[estimator, :]['kappa']['mean'].index,\n",
    "            dummy_grouped.loc[estimator, :]['kappa']['mean'] - dummy_grouped.loc[estimator, :]['kappa']['sem'],\n",
    "            dummy_grouped.loc[estimator, :]['kappa']['mean'] + dummy_grouped.loc[estimator, :]['kappa']['sem'],\n",
    "            alpha=.2,\n",
    "            color=f'C{i+1}',\n",
    "        )\n",
    "\n",
    "    ax[0].hlines(0.95, 0, 200, color='k', linestyle='--')\n",
    "\n",
    "    matplotx.ylabel_top('accuracy', ax=ax[0])\n",
    "    matplotx.ylabel_top(r'F$_{1}$ macro', ax=ax[1])\n",
    "    matplotx.ylabel_top(r'F$_{1}$ micro', ax=ax[2])\n",
    "    matplotx.ylabel_top(r'$\\kappa$', ax=ax[3])\n",
    "    ax[-1].set_xlabel('number of training points', labelpad=4)\n",
    "    matplotx.line_labels(ax[0], fontsize=8)\n",
    "    fig.savefig('hea_single_vs_multiphase_classifier.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimator</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">most_frequent</th>\n",
       "      <th>10</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">stratified</th>\n",
       "      <th>10</th>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.488146</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>-0.0224</td>\n",
       "      <td>0.061136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.512246</td>\n",
       "      <td>0.029009</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.056449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.034690</td>\n",
       "      <td>0.499076</td>\n",
       "      <td>0.034555</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.034690</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.069379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.501453</td>\n",
       "      <td>0.040153</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.080018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.502295</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.044149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">uniform</th>\n",
       "      <th>10</th>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.492865</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0.055175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.491115</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>-0.0168</td>\n",
       "      <td>0.039454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.503654</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.046342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.036554</td>\n",
       "      <td>0.496159</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.036554</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>0.073108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>0.471963</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>-0.0544</td>\n",
       "      <td>0.051405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy            f1_macro           f1_micro  \\\n",
       "                             mean       std      mean       std     mean   \n",
       "estimator     train_size                                                   \n",
       "most_frequent 10           0.5000  0.000000  0.333333  0.000000   0.5000   \n",
       "              20           0.5000  0.000000  0.333333  0.000000   0.5000   \n",
       "              50           0.5000  0.000000  0.333333  0.000000   0.5000   \n",
       "              100          0.5000  0.000000  0.333333  0.000000   0.5000   \n",
       "              200          0.5000  0.000000  0.333333  0.000000   0.5000   \n",
       "stratified    10           0.4888  0.030568  0.488146  0.030612   0.4888   \n",
       "              20           0.5132  0.028224  0.512246  0.029009   0.5132   \n",
       "              50           0.4996  0.034690  0.499076  0.034555   0.4996   \n",
       "              100          0.5024  0.040009  0.501453  0.040153   0.5024   \n",
       "              200          0.5028  0.022075  0.502295  0.022070   0.5028   \n",
       "uniform       10           0.4932  0.027587  0.492865  0.027662   0.4932   \n",
       "              20           0.4916  0.019727  0.491115  0.019571   0.4916   \n",
       "              50           0.5040  0.023171  0.503654  0.023298   0.5040   \n",
       "              100          0.4968  0.036554  0.496159  0.036845   0.4968   \n",
       "              200          0.4728  0.025703  0.471963  0.025709   0.4728   \n",
       "\n",
       "                                     kappa            \n",
       "                               std    mean       std  \n",
       "estimator     train_size                              \n",
       "most_frequent 10          0.000000  0.0000  0.000000  \n",
       "              20          0.000000  0.0000  0.000000  \n",
       "              50          0.000000  0.0000  0.000000  \n",
       "              100         0.000000  0.0000  0.000000  \n",
       "              200         0.000000  0.0000  0.000000  \n",
       "stratified    10          0.030568 -0.0224  0.061136  \n",
       "              20          0.028224  0.0264  0.056449  \n",
       "              50          0.034690 -0.0008  0.069379  \n",
       "              100         0.040009  0.0048  0.080018  \n",
       "              200         0.022075  0.0056  0.044149  \n",
       "uniform       10          0.027587 -0.0136  0.055175  \n",
       "              20          0.019727 -0.0168  0.039454  \n",
       "              50          0.023171  0.0080  0.046342  \n",
       "              100         0.036554 -0.0064  0.073108  \n",
       "              200         0.025703 -0.0544  0.051405  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy       f1_macro      f1_micro      kappa     \n",
       "               mean  std      mean  std     mean  std  mean  std\n",
       "train_size                                                      \n",
       "10              0.5  0.0  0.333333  0.0      0.5  0.0   0.0  0.0\n",
       "20              0.5  0.0  0.333333  0.0      0.5  0.0   0.0  0.0\n",
       "50              0.5  0.0  0.333333  0.0      0.5  0.0   0.0  0.0\n",
       "100             0.5  0.0  0.333333  0.0      0.5  0.0   0.0  0.0\n",
       "200             0.5  0.0  0.333333  0.0      0.5  0.0   0.0  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_grouped.loc['most_frequent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f3b9074e5baa1438c27e2ea813f7f53b7516c83bd70840b6d64eae6820ee5df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
